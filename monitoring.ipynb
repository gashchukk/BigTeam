{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee87cf37-e9cb-4b6e-8811-87b30c3c1c54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for view in spark.catalog.listTables():\n",
    "    if view.name.startswith(\"_sqldf\"):\n",
    "        spark.catalog.dropTempView(view.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b084f1c7-e923-45cc-bd1e-414166dbe69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "USE CATALOG sandwich;\n",
    "CREATE SCHEMA IF NOT EXISTS monitoring;\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS monitoring.data_quality_log (\n",
    "  table_name STRING,\n",
    "  source_layer STRING,\n",
    "  target_layer STRING,\n",
    "  load_time TIMESTAMP,\n",
    "  source_count BIGINT,\n",
    "  target_count BIGINT,\n",
    "  row_count_status STRING,\n",
    "  data_match BOOLEAN\n",
    ");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8a8b4e2-3917-49da-9533-81f1756ff23f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "bronze_schema = \"sandwich.bronze\"\n",
    "silver_schema = \"sandwich.silver\"\n",
    "monitoring_table = \"sandwich.monitoring.data_quality_log\"\n",
    "\n",
    "spark.sql(\"USE CATALOG sandwich\")\n",
    "\n",
    "tables = [row.tableName for row in spark.sql(f\"SHOW TABLES IN {bronze_schema}\").collect()]\n",
    "\n",
    "for tbl in tables:\n",
    "    print(f\"üîç Checking table: {tbl}\")\n",
    "\n",
    "    bronze_count = spark.sql(f\"SELECT COUNT(*) AS cnt FROM {bronze_schema}.{tbl}\").collect()[0]['cnt']\n",
    "    silver_count = spark.sql(f\"SELECT COUNT(*) AS cnt FROM {silver_schema}.{tbl}\").collect()[0]['cnt']\n",
    "    row_status = \"OK\" if bronze_count == silver_count else \"MISMATCH\"\n",
    "\n",
    "    bronze_df = spark.table(f\"{bronze_schema}.{tbl}\")\n",
    "    silver_df = spark.table(f\"{silver_schema}.{tbl}\")\n",
    "    \n",
    "    common_cols = [c for c in bronze_df.columns if c in silver_df.columns]\n",
    "    bronze_df = bronze_df.select(common_cols)\n",
    "    silver_df = silver_df.select(common_cols)\n",
    "\n",
    "    diff = bronze_df.exceptAll(silver_df)\n",
    "    identical = diff.count() == 0\n",
    "\n",
    "    df = spark.createDataFrame([(\n",
    "        tbl, \"bronze\", \"silver\", datetime.now(),\n",
    "        bronze_count, silver_count, row_status, identical\n",
    "    )], [\n",
    "        \"table_name\", \"source_layer\", \"target_layer\",\n",
    "        \"load_time\", \"source_count\", \"target_count\",\n",
    "        \"row_count_status\", \"data_match\"\n",
    "    ])\n",
    "\n",
    "    df.writeTo(monitoring_table).append()\n",
    "\n",
    "print(\"Monitoring data logged successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae93d247-6129-453e-848e-81e0c3bff149",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Optional freshness check if latest order data isn‚Äôt stale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98cbe17a-0e15-43d1-89f2-bc885df37609",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE monitoring.data_freshness AS\n",
    "SELECT \n",
    "  'orders' AS table_name,\n",
    "  MAX(o_orderdate) AS latest_date,\n",
    "  CURRENT_TIMESTAMP() AS checked_at\n",
    "FROM sandwich.silver.orders;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f883728e-128f-45f9-95e4-0fa109655b72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT *\n",
    "FROM sandwich.monitoring.data_quality_log\n",
    "ORDER BY load_time DESC;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5808162203727809,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "monitoring",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
