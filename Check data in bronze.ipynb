{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60ac644b-0ce1-484d-b2d8-361419d05f64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check completeness of the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "440235f7-f1ef-494a-b993-ded08c8a8901",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_schema = \"samples.tpch\"\n",
    "target_schema = \"sandwich.bronze\"\n",
    "\n",
    "tables = [row.tableName for row in spark.sql(f\"SHOW TABLES IN {source_schema}\").collect()]\n",
    "\n",
    "for tbl in tables:\n",
    "    src_count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {source_schema}.{tbl}\").collect()[0]['cnt']\n",
    "    dst_count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {target_schema}.{tbl}\").collect()[0]['cnt']\n",
    "    \n",
    "    if src_count == dst_count:\n",
    "        print(f\"[OK] Table {tbl}: row count matches ({src_count})\")\n",
    "    else:\n",
    "        print(f\"[ERROR] Table {tbl}: source={src_count}, bronze={dst_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d346a60c-9752-47f0-9d7d-36d4cd94a653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Check accuracy of the data in the tables by hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95595a7-1408-48d6-b2b6-f3014f2c21e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "for tbl in tables:\n",
    "    src_sum = spark.table(f\"{source_schema}.{tbl}\").agg(F.sum(F.hash(\"*\"))).collect()[0][0]\n",
    "    dst_sum = spark.table(f\"{target_schema}.{tbl}\").agg(F.sum(F.hash(\"*\"))).collect()[0][0]\n",
    "    if src_sum == dst_sum:\n",
    "        print(f\"{tbl} checksum OK\")\n",
    "    else:\n",
    "        print(f\"{tbl} checksum MISMATCH\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Check data in bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
